{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import time\n",
    "\n",
    "from fast_ml.eda import eda_summary\n",
    "from fast_ml.eda import eda_numerical_variable, eda_numerical_plots, eda_numerical_plots_with_target \n",
    "from fast_ml.eda import eda_categorical_variable, eda_categorical_plots, eda_categorical_plots_with_target\n",
    "from fast_ml.missing_data_analysis import MissingDataAnalysis\n",
    "from fast_ml.utilities import display_all, reduce_memory_usage\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Data - Transaction file in CSV format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 23.2 s, sys: 7.87 s, total: 31 s\n",
      "Wall time: 32.5 s\n",
      "Memory usage of dataframe is 1775.1524047851562 MB\n",
      "Shape of dataframe is (590540, 394)\n"
     ]
    }
   ],
   "source": [
    "%time trans = pd.read_csv('train_transaction.csv')\n",
    "\n",
    "df_size = trans.memory_usage().sum() / 1024**2\n",
    "print(f'Memory usage of dataframe is {df_size} MB')\n",
    "\n",
    "print (f'Shape of dataframe is {trans.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We will use a function from fast_ml to reduce the memory usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 1775.15 MB\n",
      "Memory usage after optimization is: 542.35 MB\n",
      "Decreased by 69.4%\n",
      "CPU times: user 2min 25s, sys: 2min 57s, total: 5min 23s\n",
      "Wall time: 5min 56s\n"
     ]
    }
   ],
   "source": [
    "from fast_ml.utilities import reduce_memory_usage\n",
    "\n",
    "%time trans = reduce_memory_usage(trans, convert_to_category=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a sample dataset of 200k records from the original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.39 s, sys: 776 ms, total: 2.16 s\n",
      "Wall time: 2.43 s\n",
      "Memory usage of sample dataframe is 185.20355224609375 MB\n"
     ]
    }
   ],
   "source": [
    "# Take a sample of 200k records\n",
    "%time trans = trans.sample(n=200000)\n",
    "\n",
    "df_size = trans.memory_usage().sum() / 1024**2\n",
    "print(f'Memory usage of sample dataframe is {df_size} MB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the sample dataset in local drive - CSV format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 9s, sys: 1.32 s, total: 1min 10s\n",
      "Wall time: 1min 12s\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.makedirs('tmp', exist_ok=True)\n",
    "%time trans.to_csv('tmp/train_transaction_sample.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the sample dataset in local drive - Feather format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# little bit index alignment is required because the data we selected is randomly pulled from origian dataset\n",
    "trans.reset_index(inplace = True, drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.61 s, sys: 235 ms, total: 1.84 s\n",
      "Wall time: 904 ms\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "\n",
    "os.makedirs('tmp', exist_ok=True)\n",
    "%time trans.to_feather('tmp/train_transaction_sample')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load the saved sample data - CSV Format\n",
    "Note : dataframe size was 185 MB and observe the difference in size after we load it in from a csv format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.37 s, sys: 1.06 s, total: 8.42 s\n",
      "Wall time: 8.5 s\n",
      "Memory usage of dataframe is 601.1964111328125 MB\n",
      "Shape of dataframe is (200000, 394)\n"
     ]
    }
   ],
   "source": [
    "%time tmp1 = pd.read_csv('tmp/train_transaction_sample.csv')\n",
    "\n",
    "df_size = tmp1.memory_usage().sum() / 1024**2\n",
    "print(f'Memory usage of dataframe is {df_size} MB')\n",
    "print (f'Shape of dataframe is {tmp1.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load the saved sample data - Feather Format\n",
    "Note : dataframe size was 185 MB and observe the difference in size after we load it in from a feather format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.32 s, sys: 930 ms, total: 2.25 s\n",
      "Wall time: 1.92 s\n",
      "Memory usage of dataframe is 183.67779541015625 MB\n",
      "Shape of dataframe is (200000, 394)\n"
     ]
    }
   ],
   "source": [
    "%time trans = pd.read_feather('tmp/train_transaction_sample')\n",
    "\n",
    "df_size = trans.memory_usage().sum() / 1024**2\n",
    "print(f'Memory usage of dataframe is {df_size} MB')\n",
    "print (f'Shape of dataframe is {trans.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Data - Train, Valid, Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape : (162000, 394) \t valid shape : (20000, 394) \t test shape : (18000, 394)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Create a train, validation and test set\n",
    "train, valid = train_test_split(trans, test_size = .10)\n",
    "train, test = train_test_split(train, test_size = .10)\n",
    "\n",
    "print(f'train shape : {train.shape} \\t valid shape : {valid.shape} \\t test shape : {test.shape}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
